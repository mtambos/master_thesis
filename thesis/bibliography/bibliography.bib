@article{Andrew2013,
abstract = {We introduce Deep Canonical Correlation Analysis (DCCA), a method to learn com- plex nonlinear transformations of two views of data such that the resulting representations are highly linearly correlated. Parameters of both transformations are jointly learned to maximize the (regularized) total correlation. It can be viewed as a nonlinear extension of the linear method canonical correlation analy- sis (CCA). It is an alternative to the nonpara- metric method kernel canonical correlation analysis (KCCA) for learning correlated non- linear transformations. Unlike KCCA, DCCA does not require an inner product, and has the advantages of a parametric method: train- ing time scales well with data size and the training data need not be referenced when computing the representations of unseen in- stances. In experiments on two real-world datasets, we find that DCCA learns represen- tations with significantly higher correlation than those learned by CCA and KCCA. We also introduce a novel non-saturating sigmoid function based on the cube root that may be useful more generally in feedforward neural networks.},
author = {Andrew, Galen and Arora, Raman and Bilmes, Jeff and Livescu, Karen},
issn = {1938-7228},
journal = {Proceedings of The 30th International Conference on Machine Learning},
keywords = {canonical correlation analysis,deep l,kernel CCA},
pages = {1247--1255},
title = {{Deep Canonical Correlation Analysis}},
volume = {28},
year = {2013}
}
@article{Bengio2012,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
archivePrefix = {arXiv},
arxivId = {1206.5538},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {10.1145/1756006.1756025},
eprint = {1206.5538},
isbn = {1206.5538},
issn = {15324435},
number = {1993},
pages = {1--30},
pmid = {23787338},
title = {{Representation Learning: A Review and New Perspectives}},
url = {http://arxiv.org/abs/1206.5538},
year = {2012}
}
@article{Bengio1994,
abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.},
archivePrefix = {arXiv},
arxivId = {arXiv:1211.5063v2},
author = {Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
doi = {10.1109/72.279181},
eprint = {arXiv:1211.5063v2},
isbn = {1045-9227 VO - 5},
issn = {19410093},
journal = {IEEE Transactions on Neural Networks},
number = {2},
pages = {157--166},
pmid = {18267787},
title = {{Learning Long-Term Dependencies with Gradient Descent is Difficult}},
url = {http://arxiv.org/abs/1502.03044},
volume = {5},
year = {1994}
}
@article{Bertolini1999,
author = {Bertolini, C??dric and Paugam-Moisy, H??l??ne and Puzenat, Didier},
doi = {10.1007/BFb0098191},
isbn = {3540660690},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial neural networks,Associative memory,Cascaded processing,Connectionism,Priming},
pages = {348--356},
title = {{Priming an artificial associative memory}},
volume = {1606},
year = {1999}
}
@book{nltk,
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
publisher = {" O'Reilly Media, Inc."},
title = {{Natural language processing with Python: analyzing text with the natural language toolkit}},
year = {2009}
}
@article{Caligaris2010,
abstract = {Multimodal learning involves relating information from disparate sources. For example, Wikipedia contains text, audio and images; YouTube contains audio, video and text; and Flickr contains images and text. Our goal is to find meaningful representations of mutimodal data so as to capture as much information as possible. Hand-engineering task-specific features for single modalities (e.g. audio or vision) is by itself a difficult task and is often very time-consuming. The challenge gets significantly pronounced when the data comes from various different modalities (e.g. images and text). Thus, we propose an unsupervised learning model which uses images and tags from Flickr to learn joint features that model image and text correlations. Furthermore, we demonstrate cross-modality feature learning, in which better features for one modality (e.g. images) can be learned if multiple modalities (e.g. images and text) are present during feature learning time. In the following sections, we present the network architectures we use to learn bi-modal and cross-modal features. We describe an experimental setting which demonstrates that we are indeed able to learn features that effectively capture information from different modalities and that we can further improve on computer vision features if we have other modalities (e.g text) available during feature learning time. We then conclude and offer suggestions for further work.},
author = {Caligaris, Maurizio Calo},
journal = {Http://Cs229.Stanford.Edu/},
pages = {0--4},
title = {{Unsupervised Learning of Multimodal Features: Images and Text}},
url = {http://cs229.stanford.edu/proj2010/Calo-MultimodalDeepLearning.pdf},
year = {2010}
}
@misc{keras,
author = {Chollet, Fran{\c{c}}ois and Others},
howpublished = {$\backslash$url{\{}https://github.com/keras-team/keras{\}}},
publisher = {GitHub},
title = {{Keras}},
year = {2015}
}
@misc{tqdm,
author = {da Costa-Luis, Casper and L., Stephen and Hadrien, Mary and Korobov, Mikhail and Ivanov, Ivan and Chen, Guangshuo and Pagel, Matthew D. and Malmgren, Staffan and McCracken, Jack and Dill, Fabian and Panteleit, Daniel and Rothberg, Alex and Kottke, Albert and Halchenko, Yaroslav and Ostasevicius, Tomas and Pokharel, Shirish and VandeHaar, Peter and Wu, Kuang-che and Hurley, Ford and Persaud, Arun and Umer, Adnan},
doi = {10.5281/zenodo.1184709},
title = {tqdm/tqdm: tqdm v4.19.6},
url = {https://github.com/tqdm/tqdm/tree/v4.19.6}
}
@article{scikitimage,
author = {der Walt, Stefan and Sch{\"{o}}nberger, Johannes L and Nunez-Iglesias, Juan and Boulogne, Fran{\c{c}}ois and Warner, Joshua D and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony},
journal = {PeerJ},
pages = {e453},
publisher = {PeerJ Inc.},
title = {{scikit-image: image processing in Python}},
volume = {2},
year = {2014}
}
@misc{dictionaryCom,
author = {Dictionary.com, LLC.},
title = {{Dictionary.com}},
url = {http://www.dictionary.com},
year = {2018}
}
@inproceedings{dosovitskiy2016inverting,
author = {Dosovitskiy, Alexey and Brox, Thomas},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {4829--4837},
title = {{Inverting visual representations with convolutional networks}},
year = {2016}
}
@article{Drechsler2016,
abstract = {Many real-world optimization problems consist of several mutually dependent subproblems. If more than three optimization objectives are involved in the optimization process, the so-called Many-Objective Optimization is a challenge in the area of multi-objective optimization. Often, the objectives have different levels of importance that have to be considered. For this, relation {\$}\epsilon{\$}-Preferred has been presented, that enables to compare and rank multi-dimensional solutions. {\$}\epsilon{\$}-Preferred is controlled by a parameter {\$}\epsilon{\$} that has influence on the quality of the results. In this paper for the setting of the epsilon values three heuristics have been investigated. To demonstrate the behavior and efficiency of these methods an Evolutionary Algorithm for the multi-dimensional Nurse Rostering Problem is proposed. It is shown by experiments that former approaches are outperformed by heuristics that are based on self-adaptive mechanisms},
author = {Drechsler, Nicole},
doi = {10.1007/978-3-319-23392-5},
isbn = {978-3-319-23391-8},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
keywords = {Many-objective optimization,Nurse rostering problem,Relation {\$}\epsilon{\$}-preferred,User preferences},
number = {February 2016},
pages = {23--37},
title = {{Computational Intelligence}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84947733748{\&}partnerID=tZOtx3y1},
volume = {613},
year = {2016}
}
@article{Dwork2015,
abstract = {Overfitting is the bane of data analysts, even when data are plentiful. Formal approaches to understanding this problem focus on statistical inference and generalization of individual analysis procedures. Yet the practice of data analysis is an inherently interactive and adaptive process: new analyses and hypotheses are proposed after seeing the results of previous ones, parameters are tuned on the basis of obtained results, and datasets are shared and reused. An investigation of this gap has recently been initiated by the authors in (Dwork et al., 2014), where we focused on the problem of estimating expectations of adaptively chosen functions. In this paper, we give a simple and practical method for reusing a holdout (or testing) set to validate the accuracy of hypotheses produced by a learning algorithm operating on a training set. Reusing a holdout set adaptively multiple times can easily lead to overfitting to the holdout set itself. We give an algorithm that enables the validation of a large number of adaptively chosen hypotheses, while provably avoiding overfitting. We illustrate the advantages of our algorithm over the standard use of the holdout set via a simple synthetic experiment. We also formalize and address the general problem of data reuse in adaptive data analysis. We show how the differential-privacy based approach given in (Dwork et al., 2014) is applicable much more broadly to adaptive data analysis. We then show that a simple approach based on description length can also be used to give guarantees of statistical validity in adaptive settings. Finally, we demonstrate that these incomparable approaches can be unified via the notion of approximate max-information that we introduce.},
archivePrefix = {arXiv},
arxivId = {1506.02629},
author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
doi = {10.1126/science.aaa9375},
eprint = {1506.02629},
isbn = {9781450335362},
issn = {10495258},
number = {6248},
title = {{Generalization in Adaptive Data Analysis and Holdout Reuse}},
url = {http://arxiv.org/abs/1506.02629},
volume = {349},
year = {2015}
}
@article{Dwork2015a,
abstract = {Overfitting is the bane of data analysts, even when data are plentiful. Formal approaches to understanding this problem focus on statistical inference and generalization of individual analysis procedures. Yet the practice of data analysis is an inherently interactive and adaptive process: new analyses and hypotheses are proposed after seeing the results of previous ones, parameters are tuned on the basis of obtained results, and datasets are shared and reused. An investigation of this gap has recently been initiated by the authors in (Dwork et al., 2014), where we focused on the problem of estimating expectations of adaptively chosen functions. In this paper, we give a simple and practical method for reusing a holdout (or testing) set to validate the accuracy of hypotheses produced by a learning algorithm operating on a training set. Reusing a holdout set adaptively multiple times can easily lead to overfitting to the holdout set itself. We give an algorithm that enables the validation of a large number of adaptively chosen hypotheses, while provably avoiding overfitting. We illustrate the advantages of our algorithm over the standard use of the holdout set via a simple synthetic experiment. We also formalize and address the general problem of data reuse in adaptive data analysis. We show how the differential-privacy based approach given in (Dwork et al., 2014) is applicable much more broadly to adaptive data analysis. We then show that a simple approach based on description length can also be used to give guarantees of statistical validity in adaptive settings. Finally, we demonstrate that these incomparable approaches can be unified via the notion of approximate max-information that we introduce.},
archivePrefix = {arXiv},
arxivId = {1506.02629},
author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
doi = {10.1126/science.aaa9375},
eprint = {1506.02629},
isbn = {9781450335362},
issn = {10495258},
title = {{Generalization in Adaptive Data Analysis and Holdout Reuse}},
url = {http://arxiv.org/abs/1506.02629},
year = {2015}
}
@misc{spacy,
author = {ExplosionAI},
title = {{spaCy}},
url = {https://spacy.io}
}
@inproceedings{frome2013devise,
author = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Mikolov, Tomas and Others},
booktitle = {Advances in neural information processing systems},
pages = {2121--2129},
title = {{Devise: A deep visual-semantic embedding model}},
year = {2013}
}
@article{Ghiassirad2012,
abstract = {We introduce a method to find the difference of data based on convolution. The method may be used to recognize or verify training data where the number of data classes is unknown or very large in training phase or used as a kernel in an SVM or in an RBF Network. A common solution is to train a machine to maps two input patterns into a new space, which may be high dimensional, such that the output value of the machine approximates the semantic distance of input pair. The learning algorithm minimizes an error function which measures the similarity of pair of patterns presented on input layer. In the best case the error function is zero for genuine pairs and is infinity for impostor pairs. The similarity measure is done in convolutional space with Convolutional Neural Network which is robust to spatial distortions. The method is applied on AT {\&} T dataset for face verification task. {\textcopyright}2012 IEEE.},
author = {Ghiassirad, Hosseinali and Teshnehlab, Mohammad},
doi = {10.1109/IS.2012.6335144},
isbn = {9781467327824},
journal = {IS'2012 - 2012 6th IEEE International Conference Intelligent Systems, Proceedings},
number = {September 2012},
pages = {250--255},
title = {{Similarity measurement in convolutional space}},
year = {2012}
}
@article{Guo2015,
author = {Guo, Xuan},
doi = {10.1145/2732158.2732166},
isbn = {9781450333085},
journal = {Proceedings of the 20th International Conference on Intelligent User Interfaces Companion},
keywords = {interactive machine learning,multimodal data fusion,unsupervised knowledge discovery},
pages = {129--132},
title = {{Multimodal Interactive Machine Learning for User Understanding}},
year = {2015}
}
@techreport{networkx,
author = {Hagberg, Aric and Swart, Pieter and {S Chult}, Daniel},
institution = {Los Alamos National Lab.(LANL), Los Alamos, NM (United States)},
title = {{Exploring network structure, dynamics, and function using NetworkX}},
year = {2008}
}
@article{hodosh2013framing,
author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
journal = {Journal of Artificial Intelligence Research},
pages = {853--899},
title = {{Framing image description as a ranking task: Data, models and evaluation metrics}},
volume = {47},
year = {2013}
}
@article{hodosh2013framing,
author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
journal = {Journal of Artificial Intelligence Research},
pages = {853--899},
title = {{Framing image description as a ranking task: Data, models and evaluation metrics}},
volume = {47},
year = {2013}
}
@article{spacy2,
author = {Honnibal, Matthew and Montani, Ines},
journal = {To appear},
title = {{spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing}},
year = {2017}
}
@inproceedings{huiskes2008mir,
author = {Huiskes, Mark J and Lew, Michael S},
booktitle = {Proceedings of the 1st ACM international conference on Multimedia information retrieval},
organization = {ACM},
pages = {39--43},
title = {{The MIR flickr retrieval evaluation}},
year = {2008}
}
@article{matplotlib,
author = {Hunter, John D},
journal = {Computing in science {\&} engineering},
number = {3},
pages = {90--95},
publisher = {IEEE},
title = {{Matplotlib: A 2D graphics environment}},
volume = {9},
year = {2007}
}
@article{johnsson2011multimodal,
author = {Johnsson, Magnus and Balkenius, Christian and Hesslow, Germund},
journal = {Computational Intelligence},
pages = {251--263},
publisher = {Springer},
title = {{Multimodal system based on self-organizing maps}},
year = {2011}
}
@misc{scipy,
annote = {[Online; accessed ]},
author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and Others},
title = {{{\{}SciPy{\}}: Open source scientific tools for {\{}Python{\}}}},
url = {http://www.scipy.org/}
}
@article{kaiser2017one,
author = {Kaiser, Lukasz and Gomez, Aidan N and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
journal = {arXiv preprint arXiv:1706.05137},
title = {{One Model To Learn Them All}},
year = {2017}
}
@inproceedings{karpathy2014deep,
author = {Karpathy, Andrej and Joulin, Armand and Li, Fei Fei F},
booktitle = {Advances in neural information processing systems},
file = {:home/mtambos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karpathy, Joulin, Li - 2014 - Deep fragment embeddings for bidirectional image sentence mapping.pdf:pdf},
pages = {1889--1897},
title = {{Deep fragment embeddings for bidirectional image sentence mapping}},
year = {2014}
}
@article{kingma2014adam,
author = {Kingma, Diederik P and Ba, Jimmy},
journal = {arXiv preprint arXiv:1412.6980},
title = {{Adam: A method for stochastic optimization}},
year = {2014}
}
@article{Kiros2014,
abstract = {Inspired by recent advances in multimodal learning and machine translation, we introduce an encoder-decoder pipeline that learns (a): a multimodal joint embedding space with images and text and (b): a novel language model for decoding distributed representations from our space. Our pipeline effectively unifies joint image-text embedding models with multimodal neural language models. We introduce the structure-content neural language model that disentangles the structure of a sentence to its content, conditioned on representations produced by the encoder. The encoder allows one to rank images and sentences while the decoder can generate novel descriptions from scratch. Using LSTM to encode sentences, we match the state-of-the-art performance on Flickr8K and Flickr30K without using object detections. We also set new best results when using the 19-layer Oxford convolutional network. Furthermore we show that with linear encoders, the learned embedding space captures multimodal regularities in terms of vector space arithmetic e.g. *image of a blue car* - "blue" + "red" is near images of red cars. Sample captions generated for 800 images are made available for comparison.},
archivePrefix = {arXiv},
arxivId = {1411.2539},
author = {Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},
eprint = {1411.2539},
file = {:home/mtambos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiros, Salakhutdinov, Zemel - 2014 - Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models.pdf:pdf},
isbn = {9781634393973},
issn = {0142-0372},
pages = {1--13},
pmid = {1923061},
title = {{Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models}},
url = {http://arxiv.org/abs/1411.2539},
year = {2014}
}
@inproceedings{kiviluoto1996topology,
author = {Kiviluoto, Kimmo},
booktitle = {Neural Networks, 1996., IEEE International Conference on},
organization = {IEEE},
pages = {294--299},
title = {{Topology preservation in self-organizing maps}},
volume = {1},
year = {1996}
}
@article{kohonen1998self,
author = {Kohonen, Teuvo},
journal = {Neurocomputing},
number = {1},
pages = {1--6},
publisher = {Elsevier},
title = {{The self-organizing map}},
volume = {21},
year = {1998}
}
@inproceedings{krizhevsky2012imagenet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in neural information processing systems},
pages = {1097--1105},
title = {{Imagenet classification with deep convolutional neural networks}},
year = {2012}
}
@inproceedings{la1998combining,
author = {{La Cascia}, Marco and Sethi, Saratendu and Sclaroff, Stan},
booktitle = {Content-Based Access of Image and Video Libraries, 1998. Proceedings. IEEE Workshop on},
file = {:home/mtambos/google{\_}drive/Projects/masters{\_}thesis/thesis/bibliography/Combining textual and visual cues for content-based image retrieval on the world wide web.pdf:pdf},
organization = {IEEE},
pages = {24--28},
title = {{Combining textual and visual cues for content-based image retrieval on the world wide web}},
year = {1998}
}
@book{Latour2017a,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Latour, Anna L D and Babaki, Behrouz and Dries, Anton and Kimmig, Angelika and {Van den Broeck}, Guy and Nijssen, Siegfried},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66158-2_32},
eprint = {9780201398298},
isbn = {9783319661575},
issn = {16113349},
pages = {495--511},
pmid = {4520227},
title = {{Combining stochastic constraint optimization and probabilistic programming: from knowledge compilation to constraint solving}},
volume = {10416 LNCS},
year = {2017}
}
@book{Latour2017c,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Latour, Anna L D and Babaki, Behrouz and Dries, Anton and Kimmig, Angelika and {Van den Broeck}, Guy and Nijssen, Siegfried},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66158-2_32},
eprint = {9780201398298},
isbn = {9783319661575},
issn = {16113349},
pages = {495--511},
pmid = {4520227},
title = {{Combining stochastic constraint optimization and probabilistic programming: from knowledge compilation to constraint solving}},
volume = {10416 LNCS},
year = {2017}
}
@book{Latour2017b,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Latour, Anna L D and Babaki, Behrouz and Dries, Anton and Kimmig, Angelika and {Van den Broeck}, Guy and Nijssen, Siegfried},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66158-2_32},
eprint = {9780201398298},
isbn = {9783319661575},
issn = {16113349},
pages = {495--511},
pmid = {4520227},
title = {{Combining stochastic constraint optimization and probabilistic programming: from knowledge compilation to constraint solving}},
volume = {10416 LNCS},
year = {2017}
}
@book{Latour2017,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Latour, Anna L D and Babaki, Behrouz and Dries, Anton and Kimmig, Angelika and {Van den Broeck}, Guy and Nijssen, Siegfried},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66158-2_32},
eprint = {9780201398298},
isbn = {9783319661575},
issn = {16113349},
pages = {495--511},
pmid = {4520227},
title = {{Combining stochastic constraint optimization and probabilistic programming: from knowledge compilation to constraint solving}},
volume = {10416 LNCS},
year = {2017}
}
@book{Li2008,
abstract = {This paper presents our approach for automatic speech recognition (ASR) of overlapping speech. Our system consists of two principal components: a speech separation component and a feature estmation component. In the speech separation phase, we first estimated the speakers position, and then the speaker location information is used in a GSC-configured beamformer with a minimum mutual information (MMI) criterion, followed by a Zelinski and binary-masking post-filter, to separate the speech of different speakers. In the feature estimation phase, the neural networks are trained to learn the mapping from the features extracted from the pre-separated speech to those extracted from the close-talking microphone speech signal. The outputs of the neural networks are then used to generate acoustic features, which are subsequently used in acoustic model adaptation and system evaluation. The proposed approach is evaluated through ASR experiments on the PASCAL Speech Separation Challenge II (SSC2) corpus. We demonstrate that our system provides large improvements in recognition accuracy compared with a single distant microphone case and the performance of ASR system can be significantly improved both through the use of MMI beamforming and feature mapping approaches.},
author = {Li, Weifeng and Kumatani, Kenichi and Dines, John and Magimai-doss, Mathew},
booktitle = {Network},
doi = {10.1007/978-3-540-85853-9_10},
isbn = {978-3-540-85853-9},
keywords = {PASCAL,mi-,neural network,speech recognition,speech separation},
pages = {110--118},
pmid = {15379397},
title = {{A Neural Network Based Regresion Approach for Recognizing Simultaneous Speech}},
url = {http://opac.inria.fr/record=b1126864{\%}5Cnhttp://link.springer.com/10.1007/3-540-68339-9{\_}34},
year = {2008}
}
@misc{convnets-keras,
author = {Lunardog, Leszek},
title = {{convnet-keras GitHub repository}},
url = {https://github.com/lunardog/convnets-keras},
urldate = {2018-03-15}
}
@misc{tensorflow,
annote = {Software available from tensorflow.org},
author = {Mart$\backslash$'$\backslash$in{\~{}}Abadi and Ashish{\~{}}Agarwal and Paul{\~{}}Barham and Eugene{\~{}}Brevdo and Zhifeng{\~{}}Chen and Craig{\~{}}Citro and Greg{\~{}}S.{\~{}}Corrado and Andy{\~{}}Davis and Jeffrey{\~{}}Dean and Matthieu{\~{}}Devin and Sanjay{\~{}}Ghemawat and Ian{\~{}}Goodfellow and Andrew{\~{}}Harp and Geoffrey{\~{}}Irving and Michael{\~{}}Isard and Jia, Yangqing and Rafal{\~{}}Jozefowicz and Lukasz{\~{}}Kaiser and Manjunath{\~{}}Kudlur and Josh{\~{}}Levenberg and Dandelion{\~{}}Man{\'{e}} and Rajat{\~{}}Monga and Sherry{\~{}}Moore and Derek{\~{}}Murray and Chris{\~{}}Olah and Mike{\~{}}Schuster and Jonathon{\~{}}Shlens and Benoit{\~{}}Steiner and Ilya{\~{}}Sutskever and Kunal{\~{}}Talwar and Paul{\~{}}Tucker and Vincent{\~{}}Vanhoucke and Vijay{\~{}}Vasudevan and Fernanda{\~{}}Vi{\'{e}}gas and Oriol{\~{}}Vinyals and Pete{\~{}}Warden and Martin{\~{}}Wattenberg and Martin{\~{}}Wicke and Yuan{\~{}}Yu and Xiaoqiang{\~{}}Zheng},
title = {{{\{}TensorFlow{\}}: Large-Scale Machine Learning on Heterogeneous Systems}},
url = {https://www.tensorflow.org/},
year = {2015}
}
@article{McFee2010,
abstract = {In many applications involving multi-media data, the definition of similarity between items is integral to several key tasks, e.g., nearest-neighbor retrieval, classification, and recommendation. Data in such regimes typically exhibits multiple modalities, such as acoustic and visual content of video. Integrating such heterogeneous data to form a holistic similarity space is therefore a key challenge to be overcome in many real-world applications. We present a novel multiple kernel learning technique for integrating heterogeneous data into a single, unified similarity space. Our algorithm learns an optimal ensemble of kernel transfor- mations which conform to measurements of human perceptual similarity, as expressed by relative comparisons. To cope with the ubiquitous problems of subjectivity and inconsistency in multi- media similarity, we develop graph-based techniques to filter similarity measurements, resulting in a simplified and robust training procedure.},
archivePrefix = {arXiv},
arxivId = {1008.5163},
author = {McFee, Brian and Lanckriet, Gert},
eprint = {1008.5163},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Metric Learning},
number = {12},
pages = {491--523},
title = {{Learning Multi-modal Similarity}},
url = {http://arxiv.org/abs/1008.5163},
volume = {cs.AI},
year = {2010}
}
@inproceedings{pandas,
author = {McKinney, Wes and Others},
booktitle = {Proceedings of the 9th Python in Science Conference},
organization = {Austin, TX},
pages = {51--56},
title = {{Data structures for statistical computing in python}},
volume = {445},
year = {2010}
}
@article{Mikolov2013,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
journal = {arXiv},
keywords = {Machine Learning,NLP},
mendeley-tags = {Machine Learning,NLP},
month = {jan},
pages = {1301.3781},
title = {{Efficient Estimation of Word Representations in Vector Space}},
url = {http://arxiv.org/abs/1301.3781},
year = {2013}
}
@inproceedings{mikolov2013distributed,
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in neural information processing systems},
pages = {3111--3119},
title = {{Distributed representations of words and phrases and their compositionality}},
year = {2013}
}
@inproceedings{mikolov2013linguistic,
author = {Mikolov, Tomas and Yih, Wen-tau and Zweig, Geoffrey},
booktitle = {hlt-Naacl},
pages = {746--751},
title = {{Linguistic regularities in continuous space word representations.}},
volume = {13},
year = {2013}
}
@misc{miller1998wordnet,
author = {Miller, George and Fellbaum, Christiane},
publisher = {MIT Press Cambridge},
title = {{Wordnet: An electronic lexical database}},
year = {1998}
}
@inproceedings{ngiam2011multimodal,
author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
booktitle = {Proceedings of the 28th international conference on machine learning (ICML-11)},
pages = {689--696},
title = {{Multimodal deep learning}},
year = {2011}
}
@article{norouzi2013zero,
author = {Norouzi, Mohammad and Mikolov, Tomas and Bengio, Samy and Singer, Yoram and Shlens, Jonathon and Frome, Andrea and Corrado, Greg S and Dean, Jeffrey},
journal = {arXiv preprint arXiv:1312.5650},
title = {{Zero-shot learning by convex combination of semantic embeddings}},
year = {2013}
}
@book{numpy,
author = {Oliphant, Travis E},
publisher = {Trelgol Publishing USA},
title = {{A guide to NumPy}},
volume = {1},
year = {2006}
}
@article{Paplinski2005,
abstract = {We introduce a novel system of interconnected Self-Organizing Maps that can be used to build feedforward and recurrent networks of maps. Prime application of interconnected maps is in modelling systems that operate with multimodal data as for example in visual and auditory cortices and multimodal association areas in cortex. A detailed example of animal categorization in which the feedworward network of self-organizing maps is employed is presented, In the example we operate with 18-dimensional data projected up on the 19-dimensional hyper-sphere so that the "dot-product" learning law can be used. One potential benefit of the multimodal map is that it allows a rich structure of parallel unimodal processing with many maps involved, followed by convergence into multimodal maps. More complex stimuli can therefore be processed without a growing map size. {\textcopyright}Springer-Verlag Berlin Heidelberg 2005.},
author = {Papli{\'{n}}ski, A P and Gustafsson, Lennart},
file = {:home/mtambos/google{\_}drive/Projects/masters{\_}thesis/thesis/bibliography/Multimodal FeedForward Self-organizing Maps.pdf:pdf},
isbn = {3540308180},
issn = {03029743},
journal = {Computational Intelligence and Security},
pages = {81--88},
title = {{Multimodal feedforward self-organizing maps}},
url = {http://link.springer.com/chapter/10.1007/11596448{\_}11},
year = {2005}
}
@article{scikitlearn,
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Others},
journal = {Journal of machine learning research},
number = {Oct},
pages = {2825--2830},
title = {{Scikit-learn: Machine learning in Python}},
volume = {12},
year = {2011}
}
@inproceedings{pennington2014glove,
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
booktitle = {Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
file = {:home/mtambos/google{\_}drive/Projects/masters{\_}thesis/thesis/bibliography/glove.pdf:pdf},
pages = {1532--1543},
title = {{Glove: Global vectors for word representation}},
year = {2014}
}
@article{ipython,
author = {P{\'{e}}rez, Fernando and Granger, Brian E},
journal = {Computing in Science {\&} Engineering},
number = {3},
publisher = {IEEE},
title = {{IPython: a system for interactive scientific computing}},
volume = {9},
year = {2007}
}
@inproceedings{plummer2015flickr30k,
author = {Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
booktitle = {Proceedings of the IEEE international conference on computer vision},
pages = {2641--2649},
title = {{Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models}},
year = {2015}
}
@misc{psychologydictionaryOrg,
author = {{Psychology Dictionary: the only Free Online Psychology Dictionary}},
title = {psychologydictionary.org},
url = {https://psychologydictionary.org},
year = {2018}
}
@article{Puzenat1995,
author = {Puzenat, Didier},
isbn = {3540594973},
issn = {16113349},
journal = {From Natural to Artificial Neural Networks, Proc. International Workshop of Artificial Neural Networks},
pages = {1--7},
title = {{Priming an artificial neural classifier}},
year = {1995}
}
@article{ILSVRC15,
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
journal = {International Journal of Computer Vision (IJCV)},
number = {3},
pages = {211--252},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
volume = {115},
year = {2015}
}
@book{Sahlgren2006,
abstract = {The word-space model is a computational model of word meaning that utilizes the distributional patterns of words collected over large text data to represent seman- tic similarity between words in terms of spatial proximity. The model has been used for over a decade, and has demonstrated its mettle in numerous experiments and applications. It is now on the verge of moving from research environments to practical deployment in commercial systems. Although extensively used and intensively investigated, our theoretical understanding of the word-space model re- mains unclear. The question this dissertation attempts to answer is what kind of semantic information does the word-space model acquire and represent? The answer is derived through an identification and discussion of the three main theoretical cornerstones of the word-space model: the geometric metaphor of meaning, the distributional methodology, and the structuralist meaning theory. It is argued that the word-space model acquires and represents two different types of relations between words syntagmatic or paradigmatic relations depending on how the distributional patterns of words are used to accumulate word spaces. The difference between syntagmatic and paradigmatic word spaces is empirically demonstrated in a number of experiments, including comparisons with thesaurus entries, association norms, a synonym test, a list of antonym pairs, and a record of part-of-speech assignments.},
author = {Sahlgren, Magnus},
booktitle = {Linguistics},
isbn = {9171552812},
issn = {1101-1335},
pages = {156},
title = {{The Word-Space Model Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces}},
year = {2006}
}
@article{Shao2012,
abstract = {[(11)C]N-Methyl lansoprazole ([(11)C]NML, 3) was synthesized and evaluated as a radiopharmaceutical for quantifying tau neurofibrillary tangle (NFT) burden using positron emission tomography (PET) imaging. [(11)C]NML was synthesized from commercially available lansoprazole in 4.6{\%} radiochemical yield (noncorrected RCY, based upon [(11)C]MeI), 99{\%} radiochemical purity, and 16095 Ci/mmol specific activity (n = 5). Log P was determined to be 2.18. A lack of brain uptake in rodent microPET imaging revealed [(11)C]NML to be a substrate for the rodent permeability-glycoprotein 1 (PGP) transporter, but this could be overcome by pretreating with cyclosporin A to block the PGP. Contrastingly, [(11)C]NML was not found to be a substrate for the primate PGP, and microPET imaging in rhesus revealed [(11)C]NML uptake in the healthy primate brain of ∼1600 nCi/cc maximum at 3 min followed by rapid egress to 500 nCi/cc. Comparative autoradiography between wild-type rats and transgenic rats expressing human tau (hTau +/+) revealed 12{\%} higher uptake of [(11)C]NML in the cortex of brains expressing human tau. Further autoradiography with tau positive brain samples from progressive supranuclear palsy (PSP) patients revealed colocalization of [(11)C]NML with tau NFTs identified using modified Bielschowsky staining. Finally, saturation binding experiments with heparin-induced tau confirmed K d and Bmax values of [(11)C]NML as 700 pM and 0.214 fmol/{\$}\mu{\$}g, respectively.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.04585v1},
author = {Shao, Xia and Carpenter, Garrett M and Desmond, Timothy J and Sherman, Phillip and Quesada, Carole A and Fawaz, Maria and Brooks, Allen F and Kilbourn, Michael R and Albin, Roger L and Frey, Kirk A and Scott, Peter J H},
doi = {10.1021/ml300216t},
eprint = {arXiv:1502.04585v1},
isbn = {9781510810587},
issn = {19485875},
journal = {ACS Medicinal Chemistry Letters},
keywords = {Alzheimer's disease,carbon-11,neuroimaging,positron emission tomography imaging,tauopathies},
number = {11},
pages = {936--941},
pmid = {24900410},
title = {{Evaluation of [11C] N-methyl lansoprazole as a radiopharmaceutical for PET imaging of tau neurofibrillary tangles}},
url = {http://arxiv.org/abs/1502.04585},
volume = {3},
year = {2012}
}
@article{sjobergintegrated,
author = {Sj{\"{o}}berg, Mats and Laaksonen, Jorma},
file = {:home/mtambos/google{\_}drive/Projects/masters{\_}thesis/thesis/bibliography/Integrated Multimodal Data Mining Using Self-Organizing Maps.pdf:pdf},
title = {{Integrated Multimodal Data Mining Using Self-Organizing Maps}}
}
@inproceedings{socher2010connecting,
author = {Socher, Richard and Fei-Fei, Li},
booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
organization = {IEEE},
pages = {966--973},
title = {{Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora}},
year = {2010}
}
@inproceedings{socher2010connecting,
author = {Socher, Richard and Fei-Fei, Li},
booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
organization = {IEEE},
pages = {966--973},
title = {{Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora}},
year = {2010}
}
@article{Song2012,
abstract = {Many human action recognition tasks involve data that can be {\$}\backslash{\$}nfactorized into multiple views such as body postures and hand shapes. These {\$}\backslash{\$}nviews often interact with each other over time, providing important cues to {\$}\backslash{\$}nunderstanding the action. We present multi-view latent variable discriminative {\$}\backslash{\$}nmodels that jointly learn both view-shared and view-specific sub-structures to {\$}\backslash{\$}ncapture the interaction between views. Knowledge about the underlying structure {\$}\backslash{\$}nof the data is formulated as a multi-chain structured latent conditional model, {\$}\backslash{\$}nexplicitly learning the interaction between multiple views using disjoint sets {\$}\backslash{\$}nof hidden variables in a discriminative manner. The chains are tied using a {\$}\backslash{\$}npredetermined topology that repeats over time. We present three topologies - {\$}\backslash{\$}nlinked, coupled, and linked-coupled - that differ in the type of interaction {\$}\backslash{\$}nbetween views that they model. We evaluate our approach on both segmented and {\$}\backslash{\$}nunsegmented human action recognition tasks, using the ArmGesture, the NATOPS, {\$}\backslash{\$}nand the ArmGesture-Continuous data. Experimental results show that our approach {\$}\backslash{\$}noutperforms previous state-of-the-art action recognition models.},
author = {Song, Yale and Morency, Louis Philippe and Davis, Randall},
doi = {10.1109/CVPR.2012.6247918},
isbn = {9781467312264},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2120--2127},
title = {{Multi-view latent variable discriminative models for action recognition}},
year = {2012}
}
@inproceedings{srivastava2012multimodal,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan R},
booktitle = {Advances in neural information processing systems},
pages = {2222--2230},
title = {{Multimodal learning with deep boltzmann machines}},
year = {2012}
}
@book{python,
author = {{Van Rossum}, Guido and {Drake Jr}, Fred L},
publisher = {Centrum voor Wiskunde en Informatica Amsterdam, The Netherlands},
title = {{Python tutorial}},
year = {1995}
}
@misc{seaborn,
author = {Waskom, Michael and Botvinnik, Olga and O'Kane, Drew and Hobson, Paul and Lukauskas, Saulius and Gemperline, David C and Augspurger, Tom and Halchenko, Yaroslav and Cole, John B. and Warmenhoven, Jordi and de Ruiter, Julian and Pye, Cameron and Hoyer, Stephan and Vanderplas, Jake and Villalba, Santi and Kunter, Gero and Quintero, Eric and Bachant, Pete and Martin, Marcel and Meyer, Kyle and Miles, Alistair and Ram, Yoav and Yarkoni, Tal and Williams, Mike Lee and Evans, Constantine and Fitzgerald, Clark and Brian and Fonnesbeck, Chris and Lee, Antony and Qalieh, Adel},
booktitle = {Doi.Org},
doi = {10.5281/zenodo.883859},
title = {{Mwaskom/Seaborn: V0.8.1 (September 2017)}},
url = {https://zenodo.org/record/883859},
year = {2017}
}
@article{Wilson2017,
abstract = {Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.},
archivePrefix = {arXiv},
arxivId = {1705.08292},
author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nathan and Recht, Benjamin},
eprint = {1705.08292},
pages = {1--14},
title = {{The Marginal Value of Adaptive Gradient Methods in Machine Learning}},
url = {http://arxiv.org/abs/1705.08292},
year = {2017}
}
@article{young2014image,
author = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
journal = {Transactions of the Association for Computational Linguistics},
pages = {67--78},
title = {{From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions}},
volume = {2},
year = {2014}
}
@article{Yusoff2012,
abstract = {In this paper, we propose a reward-based learning model inspired by the findings from a behavioural study and biologically realistic properties of spatio-temporal neural networks. The model simulates the cognitive priming effect in stimulus-stimulus-response association. Synaptic plasticity is dependent on a global reward signal that enhances the synaptic changes derived from spike-timing dependent plasticity (STDP) process. We show that by priming a network with a cue stimulus can facilitate the response to a later stimulus. The network can be trained to associate a stimulus pair (with an inter-stimulus interval) to a response, as well as to recognise the temporal sequence of the stimulus presentation.},
author = {Yusoff, Nooraini and Gr{\"{u}}ning, Andr{\'{e}}},
doi = {10.1007/978-3-642-34475-6_21},
isbn = {9783642344749},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Associative learning,Priming effect,Reward-based learning,Spiking neural networks},
number = {PART 1},
pages = {168--175},
title = {{Learning anticipation through priming in spatio-temporal neural networks}},
volume = {7663 LNCS},
year = {2012}
}
@article{Zeiler2014,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\$}\backslash{\$}etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
doi = {10.1007/978-3-319-10590-1_53},
eprint = {1311.2901},
isbn = {9783319105895},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {818--833},
pmid = {26353135},
title = {{Visualizing and understanding convolutional networks}},
url = {http://arxiv.org/abs/1506.02078},
volume = {8689 LNCS},
year = {2014}
}
